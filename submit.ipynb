{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from trainer import Trainer\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from data.dataset import Dataset\n",
    "from utils.tools import get_config, random_bbox, mask_image, is_image_file, default_loader, get_model_list, normalize\n",
    "from utils.logger import get_logger\n",
    "from model.networks import Generator\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='configs/config.yaml',\n",
    "                    help=\"training configuration\")\n",
    "parser.add_argument('--seed', type=int, help='manual seed')\n",
    "\n",
    "# Calculate PSNR for performance metric\n",
    "def calculate_psnr(original, restored, max_value=1.0):\n",
    "    mse = torch.mean((original - restored) ** 2)\n",
    "    psnr = 20 * torch.log10(max_value / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "# Calculate performance metric of validation dataset\n",
    "def validate(trainer, val_loader, config, iteration, writer, device):\n",
    "    trainer.eval()\n",
    "    total_loss_d = 0.0\n",
    "    total_loss_g = 0.0  # Add this line\n",
    "    total_loss_tv = 0.0\n",
    "    total_psnr = 0.0\n",
    "\n",
    "    iterable_val_loader = iter(val_loader)\n",
    "    trainer_module = trainer.module\n",
    "    start_iteration = trainer_module.resume(config['resume']) if config['resume'] else 1\n",
    "    \n",
    "    try:\n",
    "        ground_truth = next(iterable_val_loader)\n",
    "    except StopIteration:\n",
    "        iterable_val_loader = iter(val_loader)\n",
    "        ground_truth = next(iterable_val_loader)\n",
    "\n",
    "    # Prepare the inputs\n",
    "    bboxes = random_bbox(config, batch_size=ground_truth.size(0))\n",
    "    x, mask = mask_image(ground_truth, bboxes, config)\n",
    "    if device:\n",
    "        x = x.cuda()\n",
    "        mask = mask.cuda()\n",
    "        ground_truth = ground_truth.cuda()\n",
    "    \n",
    "    bboxes = random_bbox(config, batch_size=x.size(0))\n",
    "\n",
    "    # Perform inference\n",
    "    losses, inpainted_result, _ = trainer(x, bboxes, mask, ground_truth)\n",
    "\n",
    "    for k in losses.keys():\n",
    "        if not losses[k].dim() == 0:\n",
    "            losses[k] = torch.mean(losses[k])\n",
    "\n",
    "    losses['d'] = losses['wgan_d'] + losses['wgan_gp'] * config['wgan_gp_lambda']\n",
    "    losses['g'] = losses['l1'] * config['l1_loss_alpha'] \\\n",
    "            + losses['ae'] * config['ae_loss_alpha'] \\\n",
    "            + losses['wgan_g'] * config['gan_loss_alpha']\n",
    "\n",
    "    # Calculate TV loss\n",
    "    tv_loss = torch.sum(torch.abs(inpainted_result[:, :, :, :-1] - inpainted_result[:, :, :, 1:])) + \\\n",
    "            torch.sum(torch.abs(inpainted_result[:, :, :-1, :] - inpainted_result[:, :, 1:, :]))\n",
    "\n",
    "    # Calculate PSNR of\n",
    "    psnr_value = calculate_psnr(ground_truth, inpainted_result)\n",
    "\n",
    "    # Accumulate the validation loss\n",
    "    total_loss_d += losses['d'].item()\n",
    "    total_loss_g += losses['g'].item()  # Add this line\n",
    "    total_loss_tv += tv_loss.item()  # Add this line\n",
    "    total_psnr += psnr_value\n",
    "\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_loss_d = total_loss_d / len(val_loader)\n",
    "    avg_loss_g = total_loss_g / len(val_loader)  # Add this line\n",
    "    avg_loss_tv = total_loss_tv / len(val_loader)\n",
    "    avg_psnr = total_psnr / len(val_loader)\n",
    "\n",
    "    # Print or log the average validation loss\n",
    "    print(f'Average Validation Loss (Discriminator): {avg_loss_d}')\n",
    "    print(f'Average Validation Loss (Generator): {avg_loss_g}')  # Add this line\n",
    "    print(f'Average Validation Loss (TV): {avg_loss_tv}')\n",
    "    print(f'Average Validation PSNR: {avg_psnr}')\n",
    "\n",
    "\n",
    "\n",
    "    writer.add_scalar('val_loss_d', avg_loss_d, iteration)\n",
    "    writer.add_scalar('val_loss_g', avg_loss_g, iteration)  # Add this line\n",
    "\n",
    "    return avg_loss_tv, avg_loss_d, avg_loss_g, avg_psnr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    config = get_config(args.config)\n",
    "\n",
    "    # Store values for visualization\n",
    "    avg_loss_tv_list = []  \n",
    "    avg_loss_g_list = []\n",
    "    avg_loss_d_list = []\n",
    "    avg_psnr_list = []\n",
    "\n",
    "    # CUDA configuration\n",
    "    cuda = config['cuda']\n",
    "    device_ids = config['gpu_ids']\n",
    "    if cuda:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in device_ids)\n",
    "        device_ids = list(range(len(device_ids)))\n",
    "        config['gpu_ids'] = device_ids\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    # Configure checkpoint path\n",
    "    checkpoint_path = os.path.join('checkpoints',\n",
    "                                config['dataset_name'],\n",
    "                                config['mask_type'] + '_' + config['expname'])\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    shutil.copy(args.config, os.path.join(checkpoint_path, os.path.basename(args.config)))\n",
    "    writer = SummaryWriter(logdir=checkpoint_path)\n",
    "    logger = get_logger(checkpoint_path)    # get logger and configure it at the first call\n",
    "\n",
    "    logger.info(\"Arguments: {}\".format(args))\n",
    "    # Set random seed\n",
    "    if args.seed is None:\n",
    "        args.seed = random.randint(1, 10000)\n",
    "    logger.info(\"Random seed: {}\".format(args.seed))\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    # Log the configuration\n",
    "    logger.info(\"Configuration: {}\".format(config))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:  # for unexpected error logging\n",
    "        # Load the dataset\n",
    "        logger.info(\"Training on dataset: {}\".format(config['dataset_name']))\n",
    "        train_dataset = Dataset(data_path=config['train_data_path'],\n",
    "                                with_subfolder=config['data_with_subfolder'],\n",
    "                                image_shape=config['image_shape'],\n",
    "                                random_crop=config['random_crop'])\n",
    "        val_dataset = Dataset(data_path=config['val_data_path'],\n",
    "                            with_subfolder=config['data_with_subfolder'],\n",
    "                                image_shape=config['image_shape'],\n",
    "                            random_crop=config['random_crop'])\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                batch_size=config['batch_size'],\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=config['num_workers'])\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                batch_size=config['batch_size'],\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=config['num_workers'])\n",
    "\n",
    "        # Define the trainer\n",
    "        trainer = Trainer(config)\n",
    "        logger.info(\"\\n{}\".format(trainer.netG))\n",
    "        logger.info(\"\\n{}\".format(trainer.localD))\n",
    "        logger.info(\"\\n{}\".format(trainer.globalD))\n",
    "\n",
    "        if cuda:\n",
    "            trainer = nn.parallel.DataParallel(trainer, device_ids=device_ids)\n",
    "            trainer_module = trainer.module\n",
    "        else:\n",
    "            trainer_module = trainer\n",
    "\n",
    "        # Get the resume iteration to restart training\n",
    "        start_iteration = trainer_module.resume(config['resume']) if config['resume'] else 1\n",
    "\n",
    "        iterable_train_loader = iter(train_loader)\n",
    "\n",
    "        time_count = time.time()\n",
    "\n",
    "        for iteration in range(start_iteration, config['niter'] + 1):\n",
    "\n",
    "\n",
    "            try:\n",
    "                ground_truth = next(iterable_train_loader)\n",
    "            except StopIteration:\n",
    "                iterable_train_loader = iter(train_loader)\n",
    "                ground_truth = next(iterable_train_loader)\n",
    "\n",
    "            # Prepare the inputs\n",
    "            bboxes = random_bbox(config, batch_size=ground_truth.size(0))\n",
    "            x, mask = mask_image(ground_truth, bboxes, config)\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                mask = mask.cuda()\n",
    "                ground_truth = ground_truth.cuda()\n",
    "\n",
    "            ###### Forward pass ######\n",
    "            compute_g_loss = iteration % config['n_critic'] == 0\n",
    "            losses, inpainted_result, offset_flow = trainer(x, bboxes, mask, ground_truth, compute_g_loss)\n",
    "            # Scalars from different devices are gathered into vectors\n",
    "            for k in losses.keys():\n",
    "                if not losses[k].dim() == 0:\n",
    "                    losses[k] = torch.mean(losses[k])\n",
    "\n",
    "            ###### Backward pass ######\n",
    "            # Update D\n",
    "            trainer_module.optimizer_d.zero_grad()\n",
    "            losses['d'] = losses['wgan_d'] + losses['wgan_gp'] * config['wgan_gp_lambda']\n",
    "            losses['d'].backward()\n",
    "            # trainer_module.optimizer_d.step()\n",
    "\n",
    "            # Update G\n",
    "            if compute_g_loss:\n",
    "                trainer_module.optimizer_g.zero_grad()\n",
    "                losses['g'] = losses['l1'] * config['l1_loss_alpha'] \\\n",
    "                            + losses['ae'] * config['ae_loss_alpha'] \\\n",
    "                            + losses['wgan_g'] * config['gan_loss_alpha']\n",
    "                losses['g'].backward()\n",
    "\n",
    "\n",
    "                trainer_module.optimizer_d.step()\n",
    "                trainer_module.optimizer_g.step()\n",
    "\n",
    "            # Log and visualization\n",
    "            log_losses = ['l1', 'ae', 'wgan_g', 'wgan_d', 'wgan_gp', 'g', 'd']\n",
    "            if iteration % config['print_iter'] == 0:\n",
    "                time_count = time.time() - time_count\n",
    "                speed = config['print_iter'] / time_count\n",
    "                speed_msg = 'speed: %.2f batches/s ' % speed\n",
    "                time_count = time.time()\n",
    "\n",
    "                message = 'Iter: [%d/%d] ' % (iteration, config['niter'])\n",
    "                for k in log_losses:\n",
    "                    v = losses.get(k, 0.)\n",
    "                    writer.add_scalar(k, v, iteration)\n",
    "                    message += '%s: %.6f ' % (k, v)\n",
    "                message += speed_msg\n",
    "                logger.info(message)\n",
    "        \n",
    "\n",
    "            if iteration % (config['viz_iter']) == 0:\n",
    "                viz_max_out = config['viz_max_out']\n",
    "                if x.size(0) > viz_max_out:\n",
    "                    viz_images = torch.stack([x[:viz_max_out], inpainted_result[:viz_max_out],\n",
    "                                            offset_flow[:viz_max_out]], dim=1)\n",
    "                else:\n",
    "                    viz_images = torch.stack([x, inpainted_result, offset_flow], dim=1)\n",
    "                viz_images = viz_images.view(-1, *list(x.size())[1:])\n",
    "                vutils.save_image(viz_images,\n",
    "                                '%s/niter_%03d.png' % (checkpoint_path, iteration),\n",
    "                                nrow=3 * 4,\n",
    "                                normalize=True)\n",
    "                \n",
    "            avg_loss_tv, avg_loss_d, avg_loss_g, avg_psnr = validate(trainer, val_loader, config, iteration, writer, device=torch.device('cuda' if cuda else 'cpu'))\n",
    "            avg_loss_tv_list.append(avg_loss_tv)  # append the value for visualization\n",
    "            avg_loss_d_list.append(avg_loss_d)\n",
    "            avg_loss_g_list.append(avg_loss_g)\n",
    "            avg_psnr_list.append(avg_psnr)\n",
    "\n",
    "            # Save the model\n",
    "            if iteration % config['snapshot_save_iter'] == 0:\n",
    "                trainer_module.save_model(checkpoint_path, iteration)\n",
    "\n",
    "\n",
    "        # Save avg_loss_tv_list as a CSV file\n",
    "        csv_file_path = ('./result/avg_loss_tv_list.csv')\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Avg Loss TV'])\n",
    "            for i, avg_loss_tv in enumerate(avg_loss_tv_list):\n",
    "                csv_writer.writerow([avg_loss_tv])\n",
    "\n",
    "        # Visualization of avg_loss_tv after training\n",
    "        plt.plot(avg_loss_tv_list, label='avg_loss_tv')\n",
    "        plt.title('Average TV Loss of Validation Set')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Average TV Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot as an image\n",
    "        plt.savefig('./result/train_tv_loss_plt')\n",
    "\n",
    "        # Close the plot\n",
    "        plt.close()\n",
    "\n",
    "        # Save avg_loss_g_list as a CSV file\n",
    "        csv_file_path = ('./result/avg_loss_g_list.csv')\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Avg Loss G'])\n",
    "            for i, avg_loss_g in enumerate(avg_loss_g_list):\n",
    "                csv_writer.writerow([avg_loss_g])\n",
    "\n",
    "        # Save avg_loss_d_list as a CSV file\n",
    "        csv_file_path = ('./result/avg_loss_d_list.csv')\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Avg Loss D'])\n",
    "            for i, avg_loss_d in enumerate(avg_loss_d_list):\n",
    "                csv_writer.writerow([avg_loss_d])\n",
    "\n",
    "        # Visualization of avg_loss_g and avg_loss_d after training\n",
    "        plt.plot(avg_loss_g_list, label='avg_loss_g')\n",
    "        plt.plot(avg_loss_d_list, label='avg_loss_d')\n",
    "        plt.title('Average Generator and Discriminator Loss of Validation Set')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Average Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot as an image\n",
    "        plt.savefig('./result/train_g_d_loss_plt')\n",
    "\n",
    "        # Close the plot\n",
    "        plt.close()\n",
    "\n",
    "        csv_file_path = ('./result/avg_val_psnr.csv')\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['Avg Loss D'])\n",
    "            for i, avg_psnr in enumerate(avg_psnr_list):\n",
    "                csv_writer.writerow([avg_psnr])\n",
    "\n",
    "        # Visualization of avg_psnr after training\n",
    "        plt.plot(avg_psnr_list, label='avg_psnr')\n",
    "        plt.title('Average PSNR of Validation Set')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Average PSNR')\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot as an image\n",
    "        plt.savefig('./result/train_psnr_plt')\n",
    "\n",
    "        # Close the plot\n",
    "        plt.close()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:  # for unexpected error logging\n",
    "        logger.error(\"{}\".format(e))\n",
    "        raise e\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Single Image (Test)\n",
    "\n",
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from model.networks import Generator\n",
    "from utils.tools import get_config, is_image_file, default_loader, normalize, get_model_list\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='configs/config.yaml', help=\"training configuration\")\n",
    "parser.add_argument('--seed', type=int, help='manual seed')\n",
    "parser.add_argument('--image', type=str)\n",
    "parser.add_argument('--output', type=str, default='output.png')\n",
    "parser.add_argument('--checkpoint_path', type=str, default='')\n",
    "parser.add_argument('--iter', type=int, default=0)\n",
    "parser.add_argument('--x1', type=int, help='Top-left x-coordinate of the rectangular region')\n",
    "parser.add_argument('--y1', type=int, help='Top-left y-coordinate of the rectangular region')\n",
    "parser.add_argument('--x2', type=int, help='Bottom-right x-coordinate of the rectangular region')\n",
    "parser.add_argument('--y2', type=int, help='Bottom-right y-coordinate of the rectangular region')\n",
    "\n",
    "\n",
    "# Define the bbox2mask function for customised bbox according to coordinates\n",
    "def bbox2mask(bbox, max_delta_h, max_delta_w, h, w):\n",
    "    mask = torch.zeros((1, h, w), dtype=torch.float32)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    y1 = y1\n",
    "    x1 = x1\n",
    "    y2 = y2\n",
    "    x2 = x2\n",
    "    mask[:, y1:y2, x1:x2] = 1.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    config = get_config(args.config)\n",
    "\n",
    "    # Extract max_delta_h and max_delta_w from max_delta_shape in config\n",
    "    max_delta_h, max_delta_w = config.get('max_delta_shape', [32, 32])\n",
    "\n",
    "    # CUDA configuration\n",
    "    cuda = config['cuda']\n",
    "    device_ids = config['gpu_ids']\n",
    "    if cuda:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in device_ids)\n",
    "        device_ids = list(range(len(device_ids)))\n",
    "        config['gpu_ids'] = device_ids\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    print(\"Arguments: {}\".format(args))\n",
    "\n",
    "    # Set random seed\n",
    "    if args.seed is None:\n",
    "        args.seed = random.randint(1, 10000)\n",
    "    print(\"Random seed: {}\".format(args.seed))\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    print(\"Configuration: {}\".format(config))\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            if is_image_file(args.image):\n",
    "                # Test a single ground-truth image with a mask at the specified rectangular region\n",
    "                ground_truth = default_loader(args.image)\n",
    "                ground_truth = transforms.ToTensor()(ground_truth)\n",
    "                ground_truth = normalize(ground_truth)\n",
    "                ground_truth = ground_truth.unsqueeze(dim=0)\n",
    "\n",
    "                # Create a mask for the specified rectangular region\n",
    "                mask = bbox2mask((args.y1, args.x1, args.y2, args.x2), max_delta_h, max_delta_w,\n",
    "                                 config['image_shape'][1], config['image_shape'][0])\n",
    "                mask = mask.unsqueeze(dim=0)\n",
    "\n",
    "                # Set checkpoint path\n",
    "                if not args.checkpoint_path:\n",
    "                    checkpoint_path = os.path.join('checkpoints', config['dataset_name'],\n",
    "                                                   config['mask_type'] + '_' + config['expname'])\n",
    "                else:\n",
    "                    checkpoint_path = args.checkpoint_path\n",
    "\n",
    "                # Define the trainer\n",
    "                netG = Generator(config['netG'], cuda, device_ids)\n",
    "                # Latest model\n",
    "                # last_model_name = get_model_list(checkpoint_path, \"gen\", iteration=args.iter)\n",
    "                last_model_name = get_model_list(checkpoint_path, \"gen_00100000.pt\")\n",
    "\n",
    "                netG.load_state_dict(torch.load(last_model_name))\n",
    "                model_iteration = args.iter\n",
    "                print(\"Resume from {} at iteration {}\".format(checkpoint_path, model_iteration))\n",
    "                \n",
    "                if cuda:\n",
    "                    netG = nn.parallel.DataParallel(netG, device_ids=device_ids)\n",
    "                    ground_truth = ground_truth.cuda()\n",
    "                    mask = mask.cuda()\n",
    "\n",
    "                # Inference\n",
    "                x1, x2, offset_flow = netG(ground_truth, mask)\n",
    "                inpainted_result = x2 * mask + ground_truth * (1. - mask)\n",
    "\n",
    "                vutils.save_image(inpainted_result, args.output, padding=0, normalize=True)\n",
    "                print(\"Saved the inpainted result to {}\".format(args.output))\n",
    "            else:\n",
    "                raise TypeError(\"{} is not an image file.\".format(args.image))\n",
    "    except Exception as e:\n",
    "        print(\"Error: {}\".format(e))\n",
    "        raise e\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
